Item Pipeline¶
Item Pipeline¶

After an item has been scraped by a spider, it is sent to the Item Pipeline which processes it through several components that are executed sequentially.
当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理

Each item pipeline component (sometimes referred as just “Item Pipeline”) is a Python class that implements a simple method.
每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类

They receive an item and perform an action over it, also deciding if the item should continue through the pipeline or be dropped and no longer processed.
他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理

Typical uses of item pipelines are:
以下是item pipeline的一些典型应用：

Writing your own item pipeline¶
编写你自己的item pipeline¶

Each item pipeline component is a Python class that must implement the following method:
编写你自己的item pipeline很简单，每个item pipeline组件是一个独立的Python类，同时必须实现以下方法:

This method is called for every item pipeline component.
每个item pipeline组件都需要调用该方法，这个方法必须返回一个 Item (或任何继承类)对象， 或是抛出 DropItem 异常，被丢弃的item将不会被之后的pipeline组件所处理

Additionally, they may also implement the following methods:
此外,他们也可以实现以下方法:

This method is called when the spider is opened.
当spider被开启时，这个方法被调用

This method is called when the spider is closed.
当spider被关闭时，这个方法被调用

If present, this classmethod is called to create a pipeline instance from a Crawler.
If present, this classmethod is called to create a pipeline instance from a Crawler. It must return a new instance of the pipeline. Crawler object provides access to all Scrapy core components like settings and signals; it is a way for pipeline to access them and hook its functionality into Scrapy.

Item pipeline example¶
Item pipeline 样例¶

Price validation and dropping items with no prices¶
验证价格，同时丢弃没有价格的item¶

Let’s take a look at the following hypothetical pipeline that adjusts the price attribute for those items that do not include VAT (price_excludes_vat attribute), and drops those items which don’t contain a price:
让我们来看一下以下这个假设的pipeline，它为那些不含税(price_excludes_vat 属性)的item调整了 price 属性，同时丢弃了那些没有价格的item:

Write items to a JSON file¶
将item写入JSON文件¶

The following pipeline stores all scraped items (from all spiders) into a single items.jl file, containing one item per line serialized in JSON format:
以下pipeline将所有(从所有spider中)爬取到的item，存储到一个独立地 items.jl 文件，每行包含一个序列化为JSON格式的item:

Note
注解

The purpose of JsonWriterPipeline is just to introduce how to write item pipelines.
JsonWriterPipeline的目的只是为了介绍怎样编写item pipeline，如果你想要将所有爬取的item都保存到同一个JSON文件， 你需要使用 Feed exports 

Duplicates filter¶
去重¶

A filter that looks for duplicate items, and drops those items that were already processed.
一个用于去重的过滤器，丢弃那些已经被处理过的item

Let’s say that our items have a unique id, but our spider returns multiples items with the same id:
让我们假设我们的item有一个唯一的id，但是我们spider返回的多个item中包含有相同的id:

Activating an Item Pipeline component¶
启用一个Item Pipeline组件¶

To activate an Item Pipeline component you must add its class to the ITEM_PIPELINES setting, like in the following example:
为了启用一个Item Pipeline组件，你必须将它的类添加到 ITEM_PIPELINES 配置，就像下面这个例子:

The integer values you assign to classes in this setting determine the order in which they run: items go through from lower valued to higher valued classes.
分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内

© Copyright 2008-2016, Scrapy developers.
© 版权所有 2008-2014, written by Scrapy developers, translated by Summer&Friends. Revision 5ed032cf.

