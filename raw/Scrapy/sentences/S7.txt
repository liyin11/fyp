Selectors¶
选择器(Selectors)¶

When you’re scraping web pages, the most common task you need to perform is to extract data from the HTML source.
当抓取网页时，你做的最常见的任务是从HTML源码中提取数据

There are several libraries available to achieve this:
现有的一些库可以达到这个目的：

Scrapy comes with its own mechanism for extracting data.
Scrapy提取数据有自己的一套机制

They’re called selectors because they “select” certain parts of the HTML document specified either by XPath or CSS expressions.
它们被称作选择器(seletors)，因为他们通过特定的 XPath 或者 CSS 表达式来“选择” HTML文件中的某个部分

XPath is a language for selecting nodes in XML documents, which can also be used with HTML.
XPath 是一门用来在XML文件中选择节点的语言，也可以用在HTML上

CSS is a language for applying styles to HTML documents.
 CSS 是一门将HTML文档样式化的语言

It defines selectors to associate those styles with specific HTML elements.
选择器由它定义，并与特定的HTML元素的样式相关连

Scrapy selectors are built over the lxml library, which means they’re very similar in speed and parsing accuracy.
Scrapy选择器构建于 lxml 库之上，这意味着它们在速度和解析准确性上非常相似

This page explains how selectors work and describes their API which is very small and simple, unlike the lxml API which is much bigger because the lxml library can be used for many other tasks, besides selecting markup documents.
本页面解释了选择器如何工作，并描述了相应的API

For a complete reference of the selectors API see Selector reference
选择器API的完全参考详见 Selector reference

Using selectors¶
使用选择器(selectors)¶

Constructing selectors¶
构造选择器(selectors)¶

Scrapy selectors are instances of Selector class constructed by passing text or TextResponse object.
Scrapy selector是以 文字(text) 或 TextResponse 构造的 Selector 实例

It automatically chooses the best parsing rules (XML vs HTML) based on input type:
 其根据输入的类型自动选择最优的分析方法(XML vs HTML):

Constructing from text:
以文字构造:

Constructing from response:
以response构造:

For convenience, response objects expose a selector on .selector attribute, it’s totally OK to use this shortcut when possible:
为了方便起见，response对象以 .selector 属性提供了一个selector， 您可以随时使用该快捷方法:

Using selectors¶
使用选择器(selectors)¶

To explain how to use the selectors we’ll use the Scrapy shell (which provides interactive testing) and an example page located in the Scrapy documentation server:
我们将使用 Scrapy shell (提供交互测试)和位于Scrapy文档服务器的一个样例页面，来解释如何使用选择器：

Here’s its HTML code:
这里是它的HTML源码:

First, let’s open the shell:
首先, 我们打开shell:

Then, after the shell loads, you’ll have the response available as response shell variable, and its attached selector in response.selector attribute.
接着，当shell载入后，您将获得名为 response 的shell变量，其为响应的response， 并且在其 response.selector 属性上绑定了一个selector

Since we’re dealing with HTML, the selector will automatically use an HTML parser.
因为我们处理的是HTML，选择器将自动使用HTML语法分析

So, by looking at the HTML code of that page, let’s construct an XPath for selecting the text inside the title tag:
那么，通过查看 HTML code 该页面的源码，我们构建一个XPath来选择title标签内的文字:

Querying responses using XPath and CSS is so common that responses include two convenience shortcuts: response.xpath() and response.css():
由于在response中使用XPath、CSS查询十分普遍，因此，Scrapy提供了两个实用的快捷方式: response.xpath() 及 response.css():

As you can see, .xpath() and .css() methods return a SelectorList instance, which is a list of new selectors.
如你所见， .xpath() 及 .css() 方法返回一个类 SelectorList 的实例, 它是一个新选择器的列表

This API can be used for quickly selecting nested data:
这个API可以用来快速的提取嵌套数据

To actually extract the textual data, you must call the selector .extract() method, as follows:
为了提取真实的原文数据，你需要调用 .extract() 方法如下:

Notice that CSS selectors can select text or attribute nodes using CSS3 pseudo-elements:
注意CSS选择器可以使用CSS3伪元素(pseudo-elements)来选择文字或者属性节点:

Now we’re going to get the base URL and some image links:
现在我们将得到根URL(base URL)和一些图片链接:

Nesting selectors¶
嵌套选择器(selectors)¶

The selection methods (.xpath() or .css()) return a list of selectors of the same type, so you can call the selection methods for those selectors too.
选择器方法( .xpath() or .css() )返回相同类型的选择器列表，因此你也可以对这些选择器调用选择器方法

Here’s an example:
下面是一个例子:

Using selectors with regular expressions¶
结合正则表达式使用选择器(selectors)¶

Selector also has a .re() method for extracting data using regular expressions.
Selector 也有一个 .re() 方法，用来通过正则表达式来提取数据

However, unlike using .xpath() or .css() methods, .re() returns a list of unicode strings.
然而，不同于使用 .xpath() 或者 .css() 方法, .re() 方法返回unicode字符串的列表

So you can’t construct nested .re() calls.
所以你无法构造嵌套式的 .re() 调用

Here’s an example used to extract image names from the HTML code above:
下面是一个例子，从上面的 HTML code 中提取图像名字:

Working with relative XPaths¶
使用相对XPaths¶

Keep in mind that if you are nesting selectors and use an XPath that starts with /, that XPath will be absolute to the document and not relative to the Selector you’re calling it from.
记住如果你使用嵌套的选择器，并使用起始为 / 的XPath，那么该XPath将对文档使用绝对路径，而且对于你调用的 Selector 不是相对路径

For example, suppose you want to extract all  elements inside  elements.
比如，假设你想提取在  元素中的所有  元素

First, you would get all  elements:
首先，你将先得到所有的  元素:

At first, you may be tempted to use the following approach, which is wrong, as it actually extracts all  elements from the document, not only those inside  elements:
开始时，你可能会尝试使用下面的错误的方法，因为它其实是从整篇文档中，而不仅仅是从那些  元素内部提取所有的  元素:

This is the proper way to do it (note the dot prefixing the .//p XPath):
下面是比较合适的处理方法(注意 .//p XPath的点前缀):

Another common case would be to extract all direct  children:
另一种常见的情况将是提取所有直系  的结果:

For more details about relative XPaths see the Location Paths section in the XPath specification.
更多关于相对XPaths的细节详见XPath说明中的 Location Paths 部分

Using EXSLT extensions¶
使用EXSLT扩展¶

Being built atop lxml, Scrapy selectors also support some EXSLT extensions and come with these pre-registered namespaces to use in XPath expressions:
因建于 lxml 之上, Scrapy选择器也支持一些 EXSLT 扩展，可以在XPath表达式中使用这些预先制定的命名空间：

Regular expressions¶
正则表达式¶

The test() function, for example, can prove quite useful when XPath’s starts-with() or contains() are not sufficient.
例如在XPath的 starts-with() 或 contains() 无法满足需求时， test() 函数可以非常有用

Example selecting links in list item with a “class” attribute ending with a digit:
例如在列表中选择有”class”元素且结尾为一个数字的链接:

Warning
警告

C library libxslt doesn’t natively support EXSLT regular expressions so lxml‘s implementation uses hooks to Python’s re module.
C语言库 libxslt 不原生支持EXSLT正则表达式，因此 lxml 在实现时使用了Python re 模块的钩子

Thus, using regexp functions in your XPath expressions may add a small performance penalty.
 因此，在XPath表达式中使用regexp函数可能会牺牲少量的性能

Set operations¶
集合操作¶

These can be handy for excluding parts of a document tree before extracting text elements for example.
集合操作可以方便地用于在提取文字元素前从文档树中去除一些部分

Example extracting microdata (sample content taken from http://schema.org/Product) with groups of itemscopes and corresponding itemprops:
例如使用itemscopes组和对应的itemprops来提取微数据(来自http://schema.org/Product的样本内容):

Here we first iterate over itemscope elements, and for each one, we look for all itemprops elements and exclude those that are themselves inside another itemscope.
在这里，我们首先在 itemscope 元素上迭代，对于其中的每一个元素，我们寻找所有的 itemprops 元素，并排除那些本身在另一个 itemscope 内的元素

Built-in Selectors reference¶
内建选择器的参考¶

response is an HtmlResponse or an XmlResponse object that will be used for selecting and extracting data.
response 是 HtmlResponse 或 XmlResponse 的一个对象，将被用来选择和提取数据

text is a unicode string or utf-8 encoded text for cases when a response isn’t available.
text 是在 response 不可用时的一个unicode字符串或utf-8编码的文字

Using text and response together is undefined behavior.
将 text 和 response 一起使用是未定义行为

type defines the selector type, it can be "html", "xml" or None (default).
type 定义了选择器类型，可以是 "html", "xml" or None (默认).

If type is None, the selector automatically chooses the best type based on response type (see below), or defaults to "html" in case it is used together with text.
如果 type 是 None ，选择器会根据 response 类型(参见下面)自动选择最佳的类型，或者在和 text 一起使用时，默认为 "html" 

If type is None and a response is passed, the selector type is inferred from the response type as follows:
如果 type 是 None ，并传递了一个 response ，选择器类型将从response类型中推导如下：

Otherwise, if type is set, the selector type will be forced and no detection will occur.
其他情况下，如果设定了 type ，选择器类型将被强制设定，而不进行检测

Find nodes matching the xpath query and return the result as a SelectorList instance with all elements flattened.
寻找可以匹配xpath query 的节点，并返回 SelectorList 的一个实例结果，单一化其所有元素

List elements implement Selector interface too.
列表元素也实现了 Selector 的接口

query is a string containing the XPATH query to apply.
query 是包含XPATH查询请求的字符串

Note
注解

For convenience, this method can be called as response.xpath()
为了方便起见，该方法也可以通过 response.xpath() 调用

Apply the given CSS selector and return a SelectorList instance.
应用给定的CSS选择器，返回 SelectorList 的一个实例

query is a string containing the CSS selector to apply.
query 是一个包含CSS选择器的字符串

In the background, CSS queries are translated into XPath queries using cssselect library and run .xpath() method.
在后台，通过 cssselect 库和运行 .xpath() 方法，CSS查询会被转换为XPath查询

Note
注解

For convenience this method can be called as response.css()
为了方便起见，该方法也可以通过 response.css() 调用

Serialize and return the matched nodes as a list of unicode strings.
串行化并将匹配到的节点返回一个unicode字符串列表

Percent encoded content is unquoted.
 结尾是编码内容的百分比

Apply the given regex and return a list of unicode strings with the matches.
应用给定的regex，并返回匹配到的unicode字符串列表

regex can be either a compiled regular expression or a string which will be compiled to a regular expression using re.compile(regex)
regex 可以是一个已编译的正则表达式，也可以是一个将被 re.compile(regex) 编译为正则表达式的字符串

Register the given namespace to be used in this Selector.
注册给定的命名空间，其将在 Selector 中使用

Without registering namespaces you can’t select or extract data from non-standard namespaces.
 不注册命名空间，你将无法从非标准命名空间中选择或提取数据

See examples below.
参见下面的例子

Remove all namespaces, allowing to traverse the document using namespace-less xpaths.
移除所有的命名空间，允许使用少量的命名空间xpaths遍历文档

See example below.
参加下面的例子

Returns True if there is any real content selected or False otherwise.
如果选择了任意的真实文档，将返回 True ，否则返回 False 

In other words, the boolean value of a Selector is given by the contents it selects.
 也就是说， Selector 的布尔值是通过它选择的内容确定的

SelectorList objects¶
SelectorList对象¶

Call the .xpath() method for each element in this list and return their results flattened as another SelectorList.
对列表中的每个元素调用 .xpath() 方法，返回结果为另一个单一化的 SelectorList 

query is the same argument as the one in Selector.xpath()
query 和 Selector.xpath() 中的参数相同

Call the .css() method for each element in this list and return their results flattened as another SelectorList.
对列表中的各个元素调用 .css() 方法，返回结果为另一个单一化的 SelectorList 

query is the same argument as the one in Selector.css()
query 和 Selector.css() 中的参数相同

Call the .extract() method for each element in this list and return their results flattened, as a list of unicode strings.
对列表中的各个元素调用 .extract() 方法，返回结果为单一化的unicode字符串列表

Call the .re() method for each element in this list and return their results flattened, as a list of unicode strings.
对列表中的各个元素调用 .re() 方法，返回结果为单一化的unicode字符串列表

returns True if the list is not empty, False otherwise.
列表非空则返回True，否则返回False

Selector examples on HTML response¶
在HTML响应上的选择器样例¶

Here’s a couple of Selector examples to illustrate several concepts.
这里是一些 Selector 的样例，用来说明一些概念

In all cases, we assume there is already a Selector instantiated with a HtmlResponse object like this:
 在所有的例子中，我们假设已经有一个通过 HtmlResponse 对象实例化的 Selector ，如下:

Select all  elements from an HTML response body, returning a list of Selector objects (ie.
从HTML响应主体中提取所有的  元素，返回:class:Selector 对象(即 SelectorList 的一个对象)的列表:

Extract the text of all  elements from an HTML response body, returning a list of unicode strings:
从HTML响应主体上提取所有  元素的文字，返回一个unicode字符串的列表:

Iterate over all  tags and print their class attribute:
在所有  标签上迭代，打印它们的类属性:

Selector examples on XML response¶
在XML响应上的选择器样例¶

Here’s a couple of examples to illustrate several concepts.
这里是一些样例，用来说明一些概念

In both cases we assume there is already a Selector instantiated with an XmlResponse object like this:
在两个例子中，我们假设已经有一个通过 XmlResponse 对象实例化的 Selector ，如下:

Select all  elements from an XML response body, returning a list of Selector objects (ie.
从XML响应主体中选择所有的  元素，返回 Selector 对象(即 SelectorList 对象)的列表:

Extract all prices from a Google Base XML feed which requires registering a namespace:
从 Google Base XML feed 中提取所有的价钱，这需要注册一个命名空间:

Removing namespaces¶
移除命名空间¶

When dealing with scraping projects, it is often quite convenient to get rid of namespaces altogether and just work with element names, to write more simple/convenient XPaths.
在处理爬虫项目时，完全去掉命名空间而仅仅处理元素名字，写更多简单/实用的XPath会方便很多

You can use the Selector.remove_namespaces() method for that.
你可以为此使用 Selector.remove_namespaces() 方法

Let’s show an example that illustrates this with GitHub blog atom feed.
让我们来看一个例子，以Github博客的atom订阅来解释这个情况

First, we open the shell with the url we want to scrape:
首先，我们使用想爬取的url来打开shell:

Once in the shell we can try selecting all  objects and see that it doesn’t work (because the Atom XML namespace is obfuscating those nodes):
一旦进入shell，我们可以尝试选择所有的  对象，可以看到没有结果(因为Atom XML命名空间混淆了这些节点):

But once we call the Selector.remove_namespaces() method, all nodes can be accessed directly by their names:
但一旦我们调用 Selector.remove_namespaces() 方法，所有的节点都可以直接通过他们的名字来访问:

If you wonder why the namespace removal procedure isn’t always called by default instead of having to call it manually, this is because of two reasons, which, in order of relevance, are:
如果你对为什么命名空间移除操作并不总是被调用，而需要手动调用有疑惑

© Copyright 2008-2016, Scrapy developers.
© 版权所有 2008-2014, written by Scrapy developers, translated by Summer&Friends. Revision 5ed032cf.

